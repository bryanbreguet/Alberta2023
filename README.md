# Alberta2023
R code for the projections and simulations for the 2023 Alberta provincial election.
This code (and files) is allowing anyone to run the same simulations I do to project the 2023 Alberta election. You can see it as a complement to the traditional 'simulator' I post on my site.
What does it do? Essentially, it does two randomizations, with some traditional projections based on the swing in-between.
The first randomization is at the provincial level. Basically, if (say) the UCP is at 45% in average in the polls, they might actually be at 42% or at 48%. So the first randomization takes care of this uncertainty. It does so by simulating N draws of size n from a multinomial distribution where the probabilities are given by the voting intentions (what most of you will likely want to change). I use N=10,000 by default but usually increase it to 20k for the final projections. Keep in mind however that the higher N, the longer it'll take. My desktop (few years old, core I5) takes a good 30 seconds to run 5-10k and more for 50k>. The code itself isn't really optimized (and I suspect some people will find it quite inefficient, borderline stupid at times), but it does what I need it to do and I can wait 1 minute once in a while. So that's all I care about.
The size n is the sample size and determines the actual margins of error. In other words, during the N simulations, how far from 45% should we go? A typical 1,000 respondent poll would have margins of error of roughly 3%. Projections, however, use a polling average which is equivalent to using one giant poll of size 5 or 6k and thus having really small MoE. On the other hand, using past averages and electoral results, I have estimated the actual, empirical accuracy of polls to be closer to 5% (see: https://www.tooclosetocall.ca/2019/09/how-accurate-are-polls-in-canada-less.html). It's quite often 2-3% but then, every once in a while, you have an Alberta 2012, BC 2013 or Quebec 2018 case where polls are really off. At the end, I use n=400 which creates MoE of 4.8%. You might think it's too wide and you can just increase n then, but I strongly suggest you keep n=400. I have calibrated this model over multiple elections and n=400 has worked perfectly so far (as far as modeling the uncertainty).
The second stage is to calculate the swing (simulated results province-wide minus the results last time around) for each party and apply this swing in every riding. This is your typical linear swing model, except you do it N times with variations. The 2023 Alberta model currently uses a basic linear swing with adjustments in case a party is far from its results in the last election (wave, collapse, etc). It then adjusts based on regional averages. For instance if the NDP is up a lot more in Calgary than what a uniform swing would predict, I adjust the projections at a rate of 50% (if the NDP is (say) at 50% in Calgary in the polls and my projections have it at 45%, I’ll add 2.5% to the NDP in Calgary). I do not fully adjust to match the regional numbers because they are very volatile and based on small sample sizes. I prefer to base my projections on the most reliable numbers, the provincial ones. However, I do recognize that some elections see large within-province adjustments and I want to take that into account. Please note that the regional adjustments are part of the ‘adjustment.csv’ file and there is no randomization of this process. It’s something I could add later on but haven’t found very useful on my experience.

You can try to be as fancy as it gets for this step (and I have in the past with regression coefficients), the truth is that what really matters is getting the voting % right in step 1. If you get that part right, your projections will likely be good. No matter how fancy your model is, if you input the wrong %, you'll be wrong (or you'll be right because you are lucky and the errors are cancelling out). The file 'adjustments' is also there to adjust for multiple factors such as losing a long term incumbent or having a star candidate this year. The file does not show you how I come up with those adjustments. If it bugs you, just replace the file with zeros. Or you can ask me on Twitter.
The third stage is a second randomization because knowing the province-wide percentages isn't enough. Even knowing the regional ones would still not allow you to perfectly predict each riding. If a region (say Calgary) has an average swing of -5 for the UCP, the actual swing in each riding could be 0% in one and -15% in another. The second randomization therefore re-samples at the riding level for every simulation. Basically, if you have (say) the UCP at 48% in riding 1 and the NDP at 46%, these two parties could actually be at 44% and 50%. The randomization will take care of those possibilities. For the second round, n=200. This creates pretty wide intervals but there as well, this is all calibrated based on past elections. There is still considerable uncertainty at the riding level even if you know the province-wide %.
The two randomizations are independent from each other. It means a party could for instance be sampled higher than its polling average but then be inefficient at the riding level. Over 10k simulations, the average won't change much but the tails will become fatter (think a situation where a party not only beats its polling number but also has a crazy efficient vote -- Like the LPC at the federal level in 2019).
How to use it? It's a R code. I personally use Rstudio as I like a more visual interface but the code should absolutely work in R itself.
Because of previous elections, the UCP is coded as 1, NDP as 2, Alberta party as 3, Liberals as 4 and Wildrose as 5. This could be modified during the campaign after we know how many candidates each party is running.
You need the code as well as a few files, all provided:
a) Results of the 2019 Alberta election by riding.
b) A file called 'adjustments' where I make manual (and systematic) adjustments at the riding level. For instance the losing a strong candidate (maybe a popular minister) or getting a new star candidate. Some adjustments can be arbitrary (hard to judge if a new candidate is a 'star' one) while others are the results of regional adjustments (using polling averages), riding-level polls or demographic changes. I also have estimated that for the main parties, losing a long term incumbent (more than 2 mandates) usually causes a drop of 5%, although it can vary a lot. The file is provided as in with no explanation. Email me if you have questions. You can also reset all the cells to 0 if you think my adjustments are stupid.
That's all for now. If you see any mistake, please let me know. If you use this code to publih anything (blog, tweet, etc), please give me (or my blog) credit. If you think this code is garbbage, make sure to mention it on Reddit.
